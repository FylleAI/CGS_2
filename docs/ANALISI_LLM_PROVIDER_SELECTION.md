# Analisi: Selezione LLM Provider nel Flusso Onboarding ‚Üí CGS

**Data**: 2025-10-16  
**Obiettivo**: Configurare tutti i payload da Onboarding per usare **Gemini Pro 2.5** (eccetto ricerca web con Perplexity)

---

## üìä SITUAZIONE ATTUALE

### üîÑ Flusso Payload: Onboarding ‚Üí CGS

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. ONBOARDING BACKEND                                               ‚îÇ
‚îÇ    PayloadBuilder.build_payload()                                   ‚îÇ
‚îÇ    ‚îú‚îÄ Crea CgsPayloadLinkedInPost o CgsPayloadNewsletter           ‚îÇ
‚îÇ    ‚îú‚îÄ metadata.requested_provider: Optional[str] = None            ‚îÇ
‚îÇ    ‚îî‚îÄ NO specifica provider/model di default                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. CGS ADAPTER                                                      ‚îÇ
‚îÇ    CgsAdapter._convert_to_cgs_request()                            ‚îÇ
‚îÇ    ‚îú‚îÄ Converte payload ‚Üí ContentGenerationRequestModel             ‚îÇ
‚îÇ    ‚îú‚îÄ Se metadata.requested_provider esiste:                       ‚îÇ
‚îÇ    ‚îÇ  request["provider"] = metadata.requested_provider            ‚îÇ
‚îÇ    ‚îî‚îÄ Altrimenti: NON specifica provider (usa default CGS)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. CGS API ENDPOINT                                                 ‚îÇ
‚îÇ    POST /api/v1/content/generate                                   ‚îÇ
‚îÇ    ContentGenerationRequestModel:                                  ‚îÇ
‚îÇ    ‚îú‚îÄ provider: str = "openai"  ‚Üê ‚ö†Ô∏è DEFAULT HARDCODED             ‚îÇ
‚îÇ    ‚îú‚îÄ model: str = "gpt-4o"     ‚Üê ‚ö†Ô∏è DEFAULT HARDCODED             ‚îÇ
‚îÇ    ‚îî‚îÄ temperature: float = 0.7                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. GENERATE CONTENT USE CASE                                       ‚îÇ
‚îÇ    GenerateContentUseCase.execute()                                ‚îÇ
‚îÇ    ‚îú‚îÄ Usa provider_config passato dal dependency injection         ‚îÇ
‚îÇ    ‚îú‚îÄ AgentExecutor riceve provider_config                         ‚îÇ
‚îÇ    ‚îî‚îÄ Tutti gli agent usano lo stesso provider_config              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. AGENT EXECUTOR                                                   ‚îÇ
‚îÇ    AgentExecutor.execute_agent()                                   ‚îÇ
‚îÇ    ‚îú‚îÄ _get_dynamic_provider_config(context)                        ‚îÇ
‚îÇ    ‚îú‚îÄ Cerca in context: provider_name, model, temperature          ‚îÇ
‚îÇ    ‚îú‚îÄ Se NON trovati ‚Üí usa self.provider_config (default)          ‚îÇ
‚îÇ    ‚îî‚îÄ Chiama llm_provider.generate_content(config=dynamic_config)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. TOOLS (Perplexity, Web Search, RAG, Image)                     ‚îÇ
‚îÇ    ‚îú‚îÄ PerplexityResearchTool: usa PERPLEXITY_API_KEY              ‚îÇ
‚îÇ    ‚îÇ  ‚îî‚îÄ Modello: "sonar-pro" (hardcoded nel tool)                ‚îÇ
‚îÇ    ‚îú‚îÄ WebSearchTool: usa SERPER_API_KEY (Google Search)           ‚îÇ
‚îÇ    ‚îú‚îÄ RAGTool: usa il provider_config dell'agent                  ‚îÇ
‚îÇ    ‚îî‚îÄ ImageGenerationTool: usa provider specifico (OpenAI/Gemini) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç PUNTI CHIAVE

### 1. **Default Provider in CGS API**

**File**: `api/rest/v1/endpoints/content.py`

```python
class ContentGenerationRequestModel(BaseModel):
    provider: str = "openai"      # ‚Üê DEFAULT
    model: str = "gpt-4o"         # ‚Üê DEFAULT
    temperature: float = 0.7
```

‚ö†Ô∏è **Problema**: Se Onboarding NON specifica `requested_provider`, CGS usa OpenAI di default.

---

### 2. **Metadata in Payload Onboarding**

**File**: `onboarding/domain/cgs_contracts.py`

```python
class CgsPayloadMetadata(BaseModel):
    source: str = Field(default="onboarding_adapter")
    dry_run: bool = Field(default=False)
    requested_provider: Optional[str] = None  # ‚Üê Pu√≤ specificare provider
    language: str = Field(default="it")
```

**File**: `onboarding/application/builders/payload_builder.py`

```python
def build_payload(
    self,
    session_id: UUID,
    trace_id: str,
    snapshot: CompanySnapshot,
    goal: OnboardingGoal,
    dry_run: bool = False,
    requested_provider: Optional[str] = None,  # ‚Üê Parametro disponibile
) -> CgsPayloadLinkedInPost | CgsPayloadNewsletter:
```

‚úÖ **Soluzione**: PayloadBuilder gi√† supporta `requested_provider`, ma NON lo usa di default.

---

### 3. **Conversione Payload ‚Üí CGS Request**

**File**: `onboarding/infrastructure/adapters/cgs_adapter.py`

```python
def _convert_to_cgs_request(
    self,
    payload: CgsPayloadLinkedInPost | CgsPayloadNewsletter,
) -> Dict[str, Any]:
    # Base request
    request = {
        "workflow_type": payload.workflow,
        "client_profile": payload.input.client_profile,
    }
    
    # Add provider if specified
    if payload.metadata.requested_provider:
        request["provider"] = payload.metadata.requested_provider
```

‚úÖ **Funziona**: Se `metadata.requested_provider` √® impostato, viene passato a CGS.

---

### 4. **Agent Executor - Dynamic Config**

**File**: `core/infrastructure/orchestration/agent_executor.py`

```python
def _get_dynamic_provider_config(self, context: Dict[str, Any]) -> ProviderConfig:
    """Get dynamic provider config from context or use default."""
    provider_name = context.get("provider_name") or context.get("provider")
    model = context.get("model")
    temperature = context.get("temperature")
    
    # Create dynamic config
    if provider_name:
        provider = LLMProvider(provider_name)
    else:
        provider = self.provider_config.provider  # ‚Üê Usa default
    
    # Use model from context or default for provider
    if not model:
        defaults = {
            LLMProvider.OPENAI: "gpt-4o",
            LLMProvider.ANTHROPIC: "claude-3-7-sonnet-latest",
            LLMProvider.DEEPSEEK: "deepseek-chat",
            LLMProvider.GEMINI: "gemini-2.5-pro",  # ‚Üê ‚úÖ Gemini supportato
        }
        model = defaults.get(provider, self.provider_config.model)
```

‚úÖ **Supporto Gemini**: AgentExecutor supporta gi√† Gemini Pro 2.5.

---

### 5. **Tools - Perplexity**

**File**: `core/infrastructure/tools/perplexity_research_tool.py`

```python
class PerplexityResearchTool:
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        timeout: int = 30,
    ):
        self.api_key = api_key or os.getenv("PERPLEXITY_API_KEY")
        self.model = model or "sonar-pro"  # ‚Üê Modello Perplexity
```

‚úÖ **Indipendente**: Perplexity usa il proprio modello, NON il provider_config degli agent.

---

### 6. **Provider Factory - Gemini**

**File**: `core/infrastructure/factories/provider_factory.py`

```python
@staticmethod
def create_provider(provider_type: LLMProvider, settings: Settings) -> LLMProviderInterface:
    if provider_type == LLMProvider.GEMINI:
        api_key = settings.gemini_api_key
        if not api_key:
            raise ValueError("Gemini API key not configured")
        return GeminiAdapter(api_key)
```

‚úÖ **Gemini Supportato**: Factory pu√≤ creare GeminiAdapter.

---

## üéØ COSA DOBBIAMO MODIFICARE

### ‚úÖ **Obiettivo**
- Tutti i payload da Onboarding usano **Gemini Pro 2.5** per gli agent
- Perplexity continua a usare **sonar-pro** per ricerca web
- Nessuna modifica ai tool (Perplexity, Web Search, RAG, Image)

---

### üìù **Modifiche Necessarie**

#### **1. PayloadBuilder - Imposta Default Provider**

**File**: `onboarding/application/builders/payload_builder.py`

**Modifica**: Nelle funzioni `_build_linkedin_payload()` e `_build_newsletter_payload()`:

```python
# Build metadata
metadata = CgsPayloadMetadata(
    source="onboarding_adapter",
    dry_run=dry_run,
    requested_provider=requested_provider or "gemini",  # ‚Üê DEFAULT: gemini
    language="it",
)
```

**Righe da modificare**:
- Riga 134-139 (LinkedIn)
- Riga 194-199 (Newsletter)

**Impatto**: 
- ‚úÖ Se `requested_provider` NON √® specificato ‚Üí usa "gemini"
- ‚úÖ Se `requested_provider` √® specificato ‚Üí usa quello (override possibile)

---

#### **2. CgsAdapter - Aggiungi Model Default**

**File**: `onboarding/infrastructure/adapters/cgs_adapter.py`

**Modifica**: In `_convert_to_cgs_request()`:

```python
# Add provider if specified
if payload.metadata.requested_provider:
    request["provider"] = payload.metadata.requested_provider
    # Add default model for Gemini
    if payload.metadata.requested_provider == "gemini":
        request["model"] = "gemini-2.5-pro"
```

**Righe da modificare**:
- Riga 132-134

**Impatto**:
- ‚úÖ Quando provider √® "gemini" ‚Üí specifica anche model "gemini-2.5-pro"
- ‚úÖ Evita che CGS usi il default "gpt-4o"

---

#### **3. (Opzionale) CGS API - Cambia Default**

**File**: `api/rest/v1/endpoints/content.py`

**Modifica**: Cambia default in `ContentGenerationRequestModel`:

```python
class ContentGenerationRequestModel(BaseModel):
    provider: str = "gemini"           # ‚Üê Cambiato da "openai"
    model: str = "gemini-2.5-pro"      # ‚Üê Cambiato da "gpt-4o"
    temperature: float = 0.7
```

**Righe da modificare**:
- Riga 36-37

**Impatto**:
- ‚ö†Ô∏è Cambia default per TUTTE le richieste CGS (non solo Onboarding)
- ‚úÖ Utile se vuoi Gemini come default globale
- ‚ùå Potrebbe rompere altri client che si aspettano OpenAI

**Raccomandazione**: NON modificare (lascia OpenAI come default globale CGS).

---

## üìã RIEPILOGO MODIFICHE

| File | Riga | Modifica | Priorit√† |
|------|------|----------|----------|
| `onboarding/application/builders/payload_builder.py` | 137 | `requested_provider or "gemini"` | ‚úÖ **ALTA** |
| `onboarding/application/builders/payload_builder.py` | 197 | `requested_provider or "gemini"` | ‚úÖ **ALTA** |
| `onboarding/infrastructure/adapters/cgs_adapter.py` | 133-136 | Aggiungi `model="gemini-2.5-pro"` | ‚úÖ **ALTA** |
| `api/rest/v1/endpoints/content.py` | 36-37 | Cambia default globale | ‚ùå **BASSA** (sconsigliato) |

---

## ‚úÖ VERIFICA POST-MODIFICA

### **Test 1: Payload Onboarding ‚Üí CGS**

```bash
# Crea sessione onboarding
curl -X POST http://localhost:8001/api/v1/onboarding/start \
  -H "Content-Type: application/json" \
  -d '{"brand_name":"Test","website":"https://test.com","goal":"linkedin_post"}'

# Verifica nei log CGS:
# ‚úÖ Deve mostrare: provider='gemini', model='gemini-2.5-pro'
```

### **Test 2: Perplexity Tool**

```bash
# Verifica nei log CGS durante ricerca:
# ‚úÖ Deve mostrare: PerplexityResearchTool usando model='sonar-pro'
# ‚úÖ Agent executor usando provider='gemini', model='gemini-2.5-pro'
```

### **Test 3: Override Provider**

```python
# Nel codice onboarding, testa override:
payload = builder.build_payload(
    session_id=session_id,
    trace_id=trace_id,
    snapshot=snapshot,
    goal=goal,
    requested_provider="openai"  # ‚Üê Override
)
# ‚úÖ Deve usare OpenAI invece di Gemini
```

---

## üîß CONFIGURAZIONE NECESSARIA

### **Environment Variables**

Assicurati che `.env` contenga:

```bash
# Gemini API Key (richiesto)
GEMINI_API_KEY=your-gemini-api-key

# Perplexity API Key (richiesto per ricerca)
PERPLEXITY_API_KEY=your-perplexity-api-key

# Vertex AI (opzionale, per Gemini via GCP)
USE_VERTEX_GEMINI=true
GCP_PROJECT_ID=your-gcp-project
GCP_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=.secrets/your-service-account.json
```

---

## üéØ PROSSIMI PASSI

1. ‚úÖ **Modifica PayloadBuilder** (2 righe)
2. ‚úÖ **Modifica CgsAdapter** (3 righe)
3. ‚úÖ **Test end-to-end** con sessione onboarding
4. ‚úÖ **Verifica log** per confermare provider/model
5. ‚úÖ **Commit modifiche** su branch Onboarding-test

---

## üìä IMPATTO

### **Vantaggi**
- ‚úÖ Gemini Pro 2.5 √® pi√π economico di GPT-4o
- ‚úÖ Gemini ha context window pi√π grande (2M tokens)
- ‚úÖ Perplexity continua a funzionare per ricerca web
- ‚úÖ Override possibile se necessario

### **Rischi**
- ‚ö†Ô∏è Gemini potrebbe avere latenza diversa da OpenAI
- ‚ö†Ô∏è Verificare qualit√† output con Gemini vs OpenAI
- ‚ö†Ô∏è Assicurarsi che GEMINI_API_KEY sia configurato

### **Compatibilit√†**
- ‚úÖ Nessun breaking change per altri client CGS
- ‚úÖ Frontend CGS continua a funzionare normalmente
- ‚úÖ Profili cliente (Siebert, etc.) non impattati

---

**Fine Analisi** üéØ

