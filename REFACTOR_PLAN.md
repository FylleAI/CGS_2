# ðŸ”„ PIANO DI REFACTOR: CGS â†’ KBA (Knowledge Base Assistant)

## ðŸ“‹ PANORAMICA DEL PROGETTO

### ðŸŽ¯ **Obiettivo Principale**
Trasformare l'attuale sistema CGS (Content Generation System) in un **KBA (Knowledge Base Assistant)** - un engine di ingestione e trasformazione dati che:

- **Input**: MÃºltiple sorgenti (PDF, URL, MD, TXT, DOCX)
- **Processo**: Workflow configurabili per trasformazione dati
- **Output**: File strutturati per Knowledge Base (es. 4 .md files)

### ðŸ—ï¸ **Principi Architetturali**
- âœ… **Preservare** il motore workflow esistente
- âœ… **Riutilizzare** l'architettura multi-agent
- âœ… **Mantenere** il sistema di logging e metriche
- âœ… **Estendere** con nuove funzionalitÃ  di parsing
- âœ… **Migliorare** l'UI per gestione file
- âœ… **Progettare per EstensibilitÃ ** - Supporto futuro per:
  - ðŸ“Š **Visualizzazioni Multiple** (dashboard, cards, grafici)
  - ðŸ”„ **Workflow di Listening** (monitoring sorgenti, auto-update)
  - ðŸŽ¯ **Segmentazione KB** (card interattive, micro-contenuti)
  - ðŸ”Œ **Plugin Architecture** (nuovi formati, transformers, viewers)

---

## ðŸ”® ARCHITETTURA PER ESTENSIBILITÃ€ FUTURA

### **ðŸŽ¯ FunzionalitÃ  Future Supportate**

#### **1. ðŸ“Š Visualizzazioni Multiple Knowledge Base**
```
Architettura Supportata:
â”œâ”€â”€ core/visualization/
â”‚   â”œâ”€â”€ renderers/
â”‚   â”‚   â”œâ”€â”€ dashboard_renderer.py    # Dashboard overview
â”‚   â”‚   â”œâ”€â”€ card_renderer.py         # Interactive cards
â”‚   â”‚   â”œâ”€â”€ graph_renderer.py        # Knowledge graphs
â”‚   â”‚   â””â”€â”€ timeline_renderer.py     # Temporal views
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ dashboard_templates/
â”‚   â”‚   â”œâ”€â”€ card_templates/
â”‚   â”‚   â””â”€â”€ graph_templates/
â”‚   â””â”€â”€ export/
â”‚       â”œâ”€â”€ html_exporter.py         # Interactive HTML
â”‚       â”œâ”€â”€ pdf_exporter.py          # Static reports
â”‚       â””â”€â”€ json_exporter.py         # Data for external tools
```

#### **2. ðŸ”„ Workflow di Listening e Auto-Update**
```
Architettura Supportata:
â”œâ”€â”€ core/listening/
â”‚   â”œâ”€â”€ monitors/
â”‚   â”‚   â”œâ”€â”€ url_monitor.py           # Web page changes
â”‚   â”‚   â”œâ”€â”€ file_monitor.py          # File system changes
â”‚   â”‚   â”œâ”€â”€ api_monitor.py           # API endpoint changes
â”‚   â”‚   â””â”€â”€ rss_monitor.py           # RSS/Atom feeds
â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â”œâ”€â”€ cron_scheduler.py        # Time-based updates
â”‚   â”‚   â”œâ”€â”€ event_scheduler.py       # Event-driven updates
â”‚   â”‚   â””â”€â”€ webhook_scheduler.py     # External triggers
â”‚   â””â”€â”€ updaters/
â”‚       â”œâ”€â”€ incremental_updater.py   # Delta updates
â”‚       â”œâ”€â”€ full_refresh_updater.py  # Complete refresh
â”‚       â””â”€â”€ smart_merger.py          # Intelligent merging
```

#### **3. ðŸŽ¯ Segmentazione e Card Interattive**
```
Architettura Supportata:
â”œâ”€â”€ core/segmentation/
â”‚   â”œâ”€â”€ segmenters/
â”‚   â”‚   â”œâ”€â”€ topic_segmenter.py       # By topic/theme
â”‚   â”‚   â”œâ”€â”€ audience_segmenter.py    # By target audience
â”‚   â”‚   â”œâ”€â”€ complexity_segmenter.py  # By complexity level
â”‚   â”‚   â””â”€â”€ format_segmenter.py      # By content format
â”‚   â”œâ”€â”€ card_generators/
â”‚   â”‚   â”œâ”€â”€ summary_card.py          # Summary cards
â”‚   â”‚   â”œâ”€â”€ qa_card.py               # Q&A cards
â”‚   â”‚   â”œâ”€â”€ tutorial_card.py         # Step-by-step cards
â”‚   â”‚   â””â”€â”€ reference_card.py        # Quick reference cards
â”‚   â””â”€â”€ interactivity/
â”‚       â”œâ”€â”€ search_engine.py         # Card search
â”‚       â”œâ”€â”€ recommendation_engine.py # Related cards
â”‚       â””â”€â”€ personalization.py      # User preferences
```

### **ðŸ”Œ Plugin Architecture Design**

#### **Workflow Plugin System**
```python
# core/plugins/workflow_plugin.py
class WorkflowPlugin(ABC):
    """Base class per workflow plugins"""

    @abstractmethod
    def get_workflow_modes(self) -> Dict[str, Any]:
        """Ritorna workflow modes supportati dal plugin"""
        pass

    @abstractmethod
    def get_transformers(self) -> Dict[str, Any]:
        """Ritorna transformers del plugin"""
        pass

    @abstractmethod
    def get_validators(self) -> Dict[str, Any]:
        """Ritorna validators del plugin"""
        pass

# Esempi di plugin futuri:
# - VisualizationPlugin (dashboard, cards, graphs)
# - ListeningPlugin (monitors, schedulers)
# - SegmentationPlugin (segmenters, card generators)
```

#### **Renderer Plugin System**
```python
# core/plugins/renderer_plugin.py
class RendererPlugin(ABC):
    """Base class per renderer plugins"""

    @abstractmethod
    def can_render(self, content_type: str, output_format: str) -> bool:
        """Verifica se puÃ² renderizzare questo tipo di contenuto"""
        pass

    @abstractmethod
    def render(self, content: Any, options: Dict[str, Any]) -> Any:
        """Renderizza il contenuto nel formato richiesto"""
        pass

# Plugin registry per auto-discovery
class PluginRegistry:
    _plugins = {}

    @classmethod
    def register_plugin(cls, plugin_type: str, plugin_instance):
        cls._plugins[plugin_type] = plugin_instance

    @classmethod
    def get_plugins(cls, plugin_type: str) -> List[Any]:
        return cls._plugins.get(plugin_type, [])
```

---

## ðŸ—‚ï¸ STRUTTURA OUTPUT MIGLIORATA

```
data/outputs/{client}/{workflow_mode}/{workflow_id}/
â”œâ”€â”€ v1.0.0/                           # Versioning semantico
â”‚   â”œâ”€â”€ manifest.json                 # Metadata del workflow
â”‚   â”œâ”€â”€ files/                        # File generati principali
â”‚   â”‚   â”œâ”€â”€ company_profile_brand_voice.md
â”‚   â”‚   â”œâ”€â”€ production_guide.md
â”‚   â”‚   â”œâ”€â”€ quality_standards.md
â”‚   â”‚   â””â”€â”€ voice_examples.md
â”‚   â”œâ”€â”€ visualizations/               # ðŸ“Š FUTURO: Visualizzazioni multiple
â”‚   â”‚   â”œâ”€â”€ dashboard.html           # Dashboard interattiva
â”‚   â”‚   â”œâ”€â”€ cards/                   # Card interattive
â”‚   â”‚   â”‚   â”œâ”€â”€ summary_cards.json
â”‚   â”‚   â”‚   â””â”€â”€ qa_cards.json
â”‚   â”‚   â”œâ”€â”€ graphs/                  # Knowledge graphs
â”‚   â”‚   â”‚   â”œâ”€â”€ topic_graph.json
â”‚   â”‚   â”‚   â””â”€â”€ relationship_graph.json
â”‚   â”‚   â””â”€â”€ exports/                 # Export formati multipli
â”‚   â”‚       â”œâ”€â”€ dashboard.pdf
â”‚   â”‚       â””â”€â”€ interactive.html
â”‚   â”œâ”€â”€ segments/                     # ðŸŽ¯ FUTURO: Contenuti segmentati
â”‚   â”‚   â”œâ”€â”€ by_topic/
â”‚   â”‚   â”‚   â”œâ”€â”€ finance_basics.json
â”‚   â”‚   â”‚   â””â”€â”€ advanced_concepts.json
â”‚   â”‚   â”œâ”€â”€ by_audience/
â”‚   â”‚   â”‚   â”œâ”€â”€ beginners.json
â”‚   â”‚   â”‚   â””â”€â”€ experts.json
â”‚   â”‚   â””â”€â”€ cards/                   # Card interattive generate
â”‚   â”‚       â”œâ”€â”€ tutorial_cards.json
â”‚   â”‚       â””â”€â”€ reference_cards.json
â”‚   â”œâ”€â”€ listening/                    # ðŸ”„ FUTURO: Configurazioni monitoring
â”‚   â”‚   â”œâ”€â”€ monitors.json            # Configurazione monitors
â”‚   â”‚   â”œâ”€â”€ schedules.json           # Schedule di aggiornamento
â”‚   â”‚   â””â”€â”€ update_history.json      # Storia aggiornamenti
â”‚   â”œâ”€â”€ metadata/                     # Dati di processo
â”‚   â”‚   â”œâ”€â”€ sources.json             # Info sorgenti originali
â”‚   â”‚   â”œâ”€â”€ processing_log.json      # Log dettagliato
â”‚   â”‚   â”œâ”€â”€ metrics.json             # Metriche performance
â”‚   â”‚   â”œâ”€â”€ relationships.json       # ðŸ“Š FUTURO: Relazioni tra contenuti
â”‚   â”‚   â””â”€â”€ analytics.json           # ðŸ“Š FUTURO: Analytics utilizzo
â”‚   â””â”€â”€ cache/                        # Cache intermedia
â”‚       â”œâ”€â”€ extracted_content/
â”‚       â”œâ”€â”€ normalized_sources/
â”‚       â”œâ”€â”€ processed_segments/       # ðŸŽ¯ FUTURO: Segmenti processati
â”‚       â””â”€â”€ rendered_views/           # ðŸ“Š FUTURO: View renderizzate
```

---

## ðŸš€ PIANO DI ESECUZIONE

### **FASE 0: PREPARAZIONE** âš™ï¸

#### **Obiettivi**
- Setup ambiente di sviluppo sicuro
- Backup e documentazione stato attuale
- Preparazione infrastruttura test

#### **Tasks**
```bash
â–¡ Creare branch feature/kba-refactor
â–¡ Backup completo stato attuale in archive/
â–¡ Documentare API esistenti (OpenAPI spec)
â–¡ Setup test environment isolato
â–¡ Creare test suite di regressione
â–¡ Configurare CI/CD per nuovo branch
```

#### **Criteri di Accettazione**
- âœ… Branch isolato funzionante
- âœ… Test suite esistente passa al 100%
- âœ… Documentazione API completa
- âœ… Backup verificato e ripristinabile

---

### **FASE 1: PULIZIA E RINOMINA** ðŸ§¹

#### **Obiettivi**
- Rimuovere vecchio flusso newsletter/content
- Preservare motore workflow core
- Aggiornare configurazioni e dipendenze

#### **Tasks**

##### **1.1 Archiviazione (NON eliminazione)**
```bash
â–¡ Spostare in archive/deprecated/:
  - core/infrastructure/workflows/handlers/*newsletter*
  - core/infrastructure/workflows/templates/*newsletter*.json
  - core/infrastructure/workflows/handlers/*article*
  - core/infrastructure/workflows/templates/*article*.json

â–¡ Mantenere temporaneamente per rollback:
  - Aggiungere flag DEPRECATED=True
  - Logging di deprecation warnings
```

##### **1.2 Aggiornamento Dipendenze**
```python
# requirements.txt - AGGIUNTE
pymupdf>=1.23.0          # PDF parsing
beautifulsoup4>=4.12.0   # HTML parsing  
readability-lxml>=0.8.1  # Content extraction
python-docx>=0.8.11      # DOCX parsing
aiofiles>=23.0.0         # Async file operations
python-magic>=0.4.27     # File type detection
```

##### **1.3 Aggiornamento Configurazioni**
```python
# core/infrastructure/config/settings.py
class Settings:
    # Configurazioni KBA Base
    KBA_MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB
    KBA_SUPPORTED_FORMATS: List[str] = ["pdf", "md", "txt", "docx", "html"]
    KBA_OUTPUT_BASE_PATH: str = "data/outputs"
    KBA_CACHE_ENABLED: bool = True
    KBA_PARALLEL_PROCESSING: bool = True

    # ðŸ”® ESTENSIBILITÃ€: Configurazioni per funzionalitÃ  future
    # Visualizations
    KBA_ENABLE_VISUALIZATIONS: bool = False  # Feature flag
    KBA_VISUALIZATION_FORMATS: List[str] = ["html", "pdf", "json"]
    KBA_DASHBOARD_THEMES: List[str] = ["default", "dark", "corporate"]

    # Listening & Monitoring
    KBA_ENABLE_LISTENING: bool = False  # Feature flag
    KBA_MONITOR_INTERVAL: int = 3600  # seconds
    KBA_MAX_MONITORS_PER_KB: int = 10

    # Segmentation & Cards
    KBA_ENABLE_SEGMENTATION: bool = False  # Feature flag
    KBA_MAX_SEGMENTS_PER_KB: int = 50
    KBA_CARD_TYPES: List[str] = ["summary", "qa", "tutorial", "reference"]

    # Plugin System
    KBA_PLUGIN_DIRECTORY: str = "plugins/"
    KBA_ENABLE_PLUGINS: bool = False  # Feature flag
    KBA_PLUGIN_TIMEOUT: int = 300  # seconds
```

##### **1.4 Aggiornamento README**
```markdown
# KBA (Knowledge Base Assistant)

Sistema di ingestione e trasformazione dati per Knowledge Base.

## FunzionalitÃ 
- Ingestione multi-formato (PDF, URL, MD, TXT, DOCX)
- Workflow configurabili di trasformazione
- Output strutturato per Knowledge Base
- UI per gestione e download file
```

#### **Criteri di Accettazione**
- âœ… Progetto builda senza errori
- âœ… Test motore workflow passano al 100%
- âœ… Vecchi endpoint marcati come deprecated
- âœ… Nuove dipendenze installate correttamente

---

### **FASE 2: NUOVO WORKFLOW KBA_INGESTION** ðŸ”§

#### **Obiettivi**
- Creare template workflow per ingestione
- Implementare handler specializzato
- Definire task pipeline completa

#### **Tasks**

##### **2.1 Template Workflow**
```json
// core/infrastructure/workflows/templates/kba_ingestion.json
{
  "workflow_info": {
    "name": "kba_ingestion",
    "version": "1.0.0",
    "description": "Knowledge Base Ingestion Pipeline",
    "category": "data_processing",
    "estimated_duration": "2-10 minutes"
  },
  "validation": {
    "required_inputs": ["client", "sources", "workflow_mode"],
    "optional_inputs": ["custom_instructions", "output_format"],
    "output_schema": "kba_output_v1.json"
  },
  "tasks": [
    {
      "id": "task1_extract",
      "name": "Source Extraction & Normalization", 
      "agent": "extractor",
      "description": "Extract and normalize content from multiple sources",
      "timeout": 300,
      "retry_count": 2,
      "dependencies": [],
      "tools": ["pdf_parser", "url_parser", "md_parser", "text_parser"]
    },
    {
      "id": "task2_enrich", 
      "name": "Content Enrichment & Cleaning",
      "agent": "enricher",
      "description": "Clean, merge and enrich extracted content",
      "timeout": 180,
      "retry_count": 1,
      "dependencies": ["task1_extract"],
      "tools": ["content_cleaner", "duplicate_detector"]
    },
    {
      "id": "task3_transform",
      "name": "Content Transformation",
      "agent": "transformer", 
      "description": "Apply workflow_mode specific transformations",
      "timeout": 600,
      "retry_count": 2,
      "dependencies": ["task2_enrich"],
      "tools": ["brand_transformer", "faq_transformer", "doc_transformer"]
    },
    {
      "id": "task4_assemble",
      "name": "File Assembly & Formatting",
      "agent": "assembler",
      "description": "Prepare final files according to output specification", 
      "timeout": 120,
      "retry_count": 1,
      "dependencies": ["task3_transform"],
      "tools": ["markdown_formatter", "json_formatter"]
    },
    {
      "id": "task5_export",
      "name": "Export & Manifest Generation",
      "agent": "exporter",
      "description": "Save files to disk and create manifest",
      "timeout": 60,
      "retry_count": 2, 
      "dependencies": ["task4_assemble"],
      "tools": ["file_manager", "manifest_generator"]
    }
  ],
  "error_handling": {
    "strategy": "graceful_degradation",
    "critical_tasks": ["task1_extract", "task5_export"],
    "fallback_outputs": ["error_report.md", "partial_results.json"]
  },
  "extensibility": {
    "plugin_hooks": [
      "pre_extraction", "post_extraction",
      "pre_transformation", "post_transformation",
      "pre_export", "post_export"
    ],
    "future_tasks": {
      "task6_visualize": {
        "enabled": false,
        "description": "Generate visualizations and dashboards",
        "agent": "visualizer",
        "dependencies": ["task5_export"]
      },
      "task7_segment": {
        "enabled": false,
        "description": "Create content segments and cards",
        "agent": "segmenter",
        "dependencies": ["task5_export"]
      },
      "task8_setup_listening": {
        "enabled": false,
        "description": "Configure monitoring and auto-updates",
        "agent": "listener",
        "dependencies": ["task5_export"]
      }
    },
    "output_extensions": {
      "visualizations": ["dashboard.html", "cards.json", "graphs.json"],
      "segments": ["topic_segments.json", "audience_segments.json"],
      "monitoring": ["monitors.json", "schedules.json"]
    }
  }
}
```

#### **Criteri di Accettazione**
- âœ… Handler esegue senza errori con sources finti
- âœ… Tutti i 5 task vengono percorsi correttamente
- âœ… Validazione input funziona per tutti i casi
- âœ… Context preparation genera tutti i metadata necessari

---

### **FASE 3: PARSERS, TRANSFORMERS E EXPORT** ðŸ”„

#### **Obiettivi**
- Implementare sistema di parsing multi-formato
- Creare transformers per workflow modes
- Sistema di export con manifest generation

#### **Tasks**

##### **3.1 Architettura Parsers**
```python
# core/ingestion/parsers/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class ParsedContent:
    """Contenuto parsato standardizzato"""
    content_md: str
    title: Optional[str] = None
    metadata: Dict[str, Any] = None
    origin: Dict[str, Any] = None
    word_count: int = 0
    language: Optional[str] = None

class BaseParser(ABC):
    """Parser base per tutti i formati"""

    @abstractmethod
    def can_parse(self, source: Dict[str, Any]) -> bool:
        """Verifica se il parser puÃ² gestire questa source"""
        pass

    @abstractmethod
    async def parse(self, source: Dict[str, Any]) -> ParsedContent:
        """Parsing principale - deve ritornare ParsedContent"""
        pass

# core/ingestion/parsers/factory.py
class ParserFactory:
    """Factory per creazione parsers"""

    _parsers = {}

    @classmethod
    def register_parser(cls, source_type: str, parser_class):
        """Registra un nuovo parser"""
        cls._parsers[source_type] = parser_class

    @classmethod
    def get_parser(cls, source_type: str) -> BaseParser:
        """Ottieni parser per tipo source"""
        parser_class = cls._parsers.get(source_type)
        if not parser_class:
            raise ValueError(f"Parser non trovato per tipo: {source_type}")
        return parser_class()
```

##### **3.2 Workflow Modes Configuration**
```python
# core/ingestion/modes.py
WORKFLOW_MODES = {
    "brand_kba_4docs": {
        "description": "Brand Knowledge Base - 4 Documents",
        "transformer": "brand_kba",
        "estimated_time": "3-7 minutes",
        "required_sources": {"min": 2, "max": 15},
        "outputs": [
            {
                "name": "company_profile_brand_voice.md",
                "type": "markdown",
                "description": "Company profile and brand voice guidelines"
            },
            {
                "name": "production_guide.md",
                "type": "markdown",
                "description": "Content production guidelines and processes"
            },
            {
                "name": "quality_standards.md",
                "type": "markdown",
                "description": "Quality standards and compliance requirements"
            },
            {
                "name": "voice_examples.md",
                "type": "markdown",
                "description": "Voice examples and cultural context"
            }
        ]
    },

    "faq_kba": {
        "description": "FAQ Knowledge Base Generation",
        "transformer": "faq_kba",
        "estimated_time": "2-5 minutes",
        "required_sources": {"min": 1, "max": 10},
        "outputs": [
            {
                "name": "faq.md",
                "type": "markdown",
                "description": "Formatted FAQ in markdown"
            },
            {
                "name": "faq.json",
                "type": "json",
                "description": "Structured FAQ data"
            }
        ]
    },

    # ðŸ”® ESTENSIBILITÃ€: Template per workflow modes futuri
    "visualization_kba": {
        "description": "Knowledge Base with Interactive Visualizations",
        "transformer": "visualization_kba",
        "estimated_time": "5-15 minutes",
        "required_sources": {"min": 2, "max": 20},
        "enabled": False,  # Feature flag
        "outputs": [
            {"name": "dashboard.html", "type": "html"},
            {"name": "knowledge_graph.json", "type": "json"},
            {"name": "interactive_cards.json", "type": "json"}
        ],
        "extensions": {
            "visualizations": True,
            "interactivity": True,
            "export_formats": ["html", "pdf", "json"]
        }
    },

    "listening_kba": {
        "description": "Self-Updating Knowledge Base with Monitoring",
        "transformer": "listening_kba",
        "estimated_time": "3-8 minutes",
        "required_sources": {"min": 1, "max": 15},
        "enabled": False,  # Feature flag
        "outputs": [
            {"name": "knowledge_base.md", "type": "markdown"},
            {"name": "monitors.json", "type": "json"},
            {"name": "update_schedule.json", "type": "json"}
        ],
        "extensions": {
            "monitoring": True,
            "auto_update": True,
            "notification": True
        }
    },

    "segmented_kba": {
        "description": "Segmented Knowledge Base with Interactive Cards",
        "transformer": "segmented_kba",
        "estimated_time": "7-20 minutes",
        "required_sources": {"min": 3, "max": 30},
        "enabled": False,  # Feature flag
        "outputs": [
            {"name": "topic_segments.json", "type": "json"},
            {"name": "audience_segments.json", "type": "json"},
            {"name": "interactive_cards.json", "type": "json"},
            {"name": "card_dashboard.html", "type": "html"}
        ],
        "extensions": {
            "segmentation": True,
            "cards": True,
            "search": True,
            "recommendations": True
        }
    }
}
```

##### **3.3 Sistema Export**
```python
# core/ingestion/export/manifest_generator.py
class ManifestGenerator:
    """Generazione manifest.json"""

    def create_manifest(self,
                       workflow_id: str,
                       context: Dict[str, Any],
                       results: Dict[str, Any]) -> str:
        """Crea manifest completo"""

        manifest = {
            "manifest_version": "1.0.0",
            "workflow": {
                "id": workflow_id,
                "version": context["version"],
                "mode": context["workflow_mode"],
                "client": context["client"],
                "created_at": context["timestamp"]
            },
            "sources": context["sources"],
            "outputs": results.get("saved_files", []),
            "processing": {
                "duration_seconds": results.get("total_duration", 0),
                "success": results.get("success", False)
            }
        }

        # Salva manifest
        manifest_path = Path(context["output_base_path"]) / "manifest.json"
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, indent=2, ensure_ascii=False)

        return str(manifest_path)
```

#### **Criteri di Accettazione**
- âœ… Parser factory funziona per tutti i formati
- âœ… PDF parsing estrae testo correttamente
- âœ… URL parsing estrae contenuto principale
- âœ… Brand transformer genera 4 file .md
- âœ… Export crea manifest.json valido
- âœ… File salvati in struttura corretta

---

### **FASE 4: ADATTAMENTO UI E API** ðŸ–¥ï¸

#### **Obiettivi**
- Adattare API esistente per KBA
- Modificare UI per gestione file
- Implementare preview e download

#### **Tasks**

##### **4.1 Nuove API Endpoints**
```python
# api/rest/v1/endpoints/kba.py
from fastapi import APIRouter, HTTPException
from typing import List, Optional
from pydantic import BaseModel

router = APIRouter(prefix="/kba", tags=["KBA"])

class KBARunRequest(BaseModel):
    client: str
    workflow_mode: str
    sources: List[Dict[str, Any]]
    custom_instructions: Optional[str] = None

@router.post("/run")
async def run_kba_workflow(request: KBARunRequest):
    """Avvia workflow KBA"""
    try:
        use_case = get_kba_use_case()
        result = await use_case.execute(request.dict())

        return {
            "workflow_id": result["workflow_id"],
            "status": "started",
            "message": "Workflow avviato con successo"
        }
    except Exception as e:
        raise HTTPException(500, f"Errore avvio workflow: {str(e)}")

@router.get("/sets")
async def list_kba_sets(client: Optional[str] = None):
    """Lista set KBA generati"""
    # Implementazione...

@router.get("/file")
async def download_file(path: str):
    """Download file specifico"""
    from fastapi.responses import FileResponse
    return FileResponse(path=path, filename=Path(path).name)
```

##### **4.2 Aggiornamento UI React**
```jsx
// web/react-app/src/components/KBA/KBADashboard.jsx
export const KBADashboard = () => {
    const [activeTab, setActiveTab] = useState('sets');
    const [sets, setSets] = useState([]);

    return (
        <div className="kba-dashboard">
            <div className="dashboard-header">
                <h1>Knowledge Base Assistant</h1>
                <div className="tab-navigation">
                    <button onClick={() => setActiveTab('sets')}>
                        Set Generati
                    </button>
                    <button onClick={() => setActiveTab('new')}>
                        Nuovo Workflow
                    </button>
                </div>
            </div>

            <div className="dashboard-content">
                {activeTab === 'sets' && <KBASetList sets={sets} />}
                {activeTab === 'new' && <KBAWorkflowForm />}
            </div>
        </div>
    );
};
```

#### **Criteri di Accettazione**
- âœ… API endpoints funzionano correttamente
- âœ… UI mostra lista set generati
- âœ… Preview file funziona per MD/JSON/TXT
- âœ… Download file funziona
- âœ… Form nuovo workflow valida input

---

## ðŸ§ª TESTING STRATEGY

### **Test di Regressione**
```bash
â–¡ Test motore workflow esistente
â–¡ Test API backward compatibility
â–¡ Test performance con file grandi
â–¡ Test sicurezza upload file
â–¡ Test gestione errori
```

### **Test Integrazione**
```bash
â–¡ Test end-to-end workflow completo
â–¡ Test parsing tutti i formati
â–¡ Test transformers con dati reali
â–¡ Test UI con workflow reali
â–¡ Test concurrent workflows
```

### **Test Performance**
```bash
â–¡ Benchmark parsing PDF grandi (>10MB)
â–¡ Test memory usage con molti file
â–¡ Test concurrent processing
â–¡ Test storage scaling
```

---

## ðŸš¨ RISCHI E MITIGAZIONI

### **Rischi Tecnici**
| Rischio | ProbabilitÃ  | Impatto | Mitigazione |
|---------|-------------|---------|-------------|
| Breaking changes motore workflow | Bassa | Alto | Test regressione completi |
| Performance parsing file grandi | Media | Medio | Streaming processing |
| Memory leaks processing | Media | Alto | Monitoring e cleanup |
| Sicurezza upload file | Alta | Alto | Validazione rigorosa |

### **Rischi di Progetto**
| Rischio | ProbabilitÃ  | Impatto | Mitigazione |
|---------|-------------|---------|-------------|
| Scope creep | Media | Medio | Piano dettagliato e fasi |
| Timeline slippage | Media | Medio | Buffer time e prioritÃ  |
| Resource availability | Bassa | Alto | Cross-training team |

---

## ðŸ“Š METRICHE DI SUCCESSO

### **FunzionalitÃ **
- âœ… Parsing accurato per tutti i formati supportati
- âœ… Workflow completion rate > 95%
- âœ… Output quality validation passa
- âœ… UI responsive e intuitiva

### **Performance**
- âœ… Processing time < 10 minuti per workflow standard
- âœ… Memory usage < 2GB per workflow
- âœ… File upload < 30 secondi per 50MB
- âœ… UI response time < 2 secondi

### **QualitÃ **
- âœ… Test coverage > 80%
- âœ… Zero critical bugs
- âœ… Documentation completa
- âœ… Error handling robusto

---

## ðŸ“… TIMELINE STIMATA

| Fase | Durata Stimata | Dipendenze |
|------|----------------|------------|
| **Fase 0: Preparazione** | 2-3 giorni | - |
| **Fase 1: Pulizia** | 3-4 giorni | Fase 0 |
| **Fase 2: Workflow** | 5-7 giorni | Fase 1 |
| **Fase 3: Parsers/Transform** | 7-10 giorni | Fase 2 |
| **Fase 4: UI/API** | 5-7 giorni | Fase 3 |
| **Testing & Polish** | 3-5 giorni | Tutte le fasi |

**Totale Stimato: 25-36 giorni lavorativi**

---

## âœ… CHECKLIST FINALE

### **Pre-Release**
```bash
â–¡ Tutti i test passano
â–¡ Performance benchmarks OK
â–¡ Security audit completato
â–¡ Documentation aggiornata
â–¡ Backup e rollback plan pronti
â–¡ User acceptance testing completato
â–¡ Load testing superato
â–¡ Error monitoring configurato
```

### **Post-Release**
```bash
â–¡ Monitoring attivo
â–¡ User feedback collection
â–¡ Performance monitoring
â–¡ Error tracking
â–¡ Usage analytics
â–¡ Documentation user finale
â–¡ Training materiali preparati
â–¡ Support procedures definite
```

---

## ðŸ”§ CONSIDERAZIONI TECNICHE AGGIUNTIVE

### **Sicurezza**
- **File Upload Validation**: Whitelist estensioni, size limits, virus scanning
- **Path Traversal Protection**: Sanitizzazione percorsi file
- **Input Sanitization**: Validazione rigorosa tutti gli input
- **Rate Limiting**: Protezione contro abuse API
- **Authentication**: Sistema di autenticazione per API sensibili

### **ScalabilitÃ **
- **Horizontal Scaling**: Design per multiple instances
- **Database Optimization**: Indexing e query optimization
- **Caching Strategy**: Redis per cache distribuita
- **Load Balancing**: Nginx per distribuzione carico
- **Monitoring**: Prometheus + Grafana per metriche

### **ManutenibilitÃ **
- **Code Documentation**: Docstrings completi
- **API Documentation**: OpenAPI/Swagger aggiornato
- **Logging Strategy**: Structured logging con correlation IDs
- **Error Handling**: Consistent error responses
- **Version Management**: Semantic versioning per API

### **ðŸ”® EstensibilitÃ  Architetturale**

#### **Plugin System Design**
```python
# Architettura per plugin system completo
core/plugins/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ workflow_plugin.py      # Base per workflow plugins
â”‚   â”œâ”€â”€ renderer_plugin.py      # Base per renderer plugins
â”‚   â”œâ”€â”€ monitor_plugin.py       # Base per monitoring plugins
â”‚   â””â”€â”€ transformer_plugin.py   # Base per transformer plugins
â”œâ”€â”€ registry/
â”‚   â”œâ”€â”€ plugin_registry.py      # Registry centrale
â”‚   â”œâ”€â”€ plugin_loader.py        # Caricamento dinamico
â”‚   â””â”€â”€ plugin_validator.py     # Validazione plugins
â””â”€â”€ hooks/
    â”œâ”€â”€ workflow_hooks.py       # Hook points nei workflow
    â”œâ”€â”€ api_hooks.py            # Hook points nelle API
    â””â”€â”€ ui_hooks.py             # Hook points nell'UI
```

#### **Event-Driven Architecture**
```python
# Sistema eventi per estensibilitÃ 
core/events/
â”œâ”€â”€ event_bus.py               # Event bus centrale
â”œâ”€â”€ event_types.py             # Definizione tipi eventi
â”œâ”€â”€ listeners/
â”‚   â”œâ”€â”€ workflow_listener.py   # Eventi workflow
â”‚   â”œâ”€â”€ kb_listener.py         # Eventi knowledge base
â”‚   â””â”€â”€ user_listener.py       # Eventi utente
â””â”€â”€ handlers/
    â”œâ”€â”€ notification_handler.py # Notifiche
    â”œâ”€â”€ analytics_handler.py    # Analytics
    â””â”€â”€ audit_handler.py        # Audit trail
```

#### **Microservices Ready**
```python
# Preparazione per architettura microservices
services/
â”œâ”€â”€ core_service/              # Servizio core workflow
â”œâ”€â”€ parsing_service/           # Servizio parsing dedicato
â”œâ”€â”€ visualization_service/     # Servizio visualizzazioni (futuro)
â”œâ”€â”€ monitoring_service/        # Servizio monitoring (futuro)
â”œâ”€â”€ segmentation_service/      # Servizio segmentazione (futuro)
â””â”€â”€ notification_service/      # Servizio notifiche (futuro)
```

#### **API Versioning Strategy**
```python
# Supporto multiple versioni API
api/
â”œâ”€â”€ v1/                        # Versione corrente
â”œâ”€â”€ v2/                        # Versione futura (visualizations)
â”œâ”€â”€ v3/                        # Versione futura (listening)
â””â”€â”€ common/                    # Componenti condivisi
    â”œâ”€â”€ auth/
    â”œâ”€â”€ validation/
    â””â”€â”€ serialization/
```

#### **Database Schema Evolution**
```sql
-- Schema estensibile per funzionalitÃ  future
-- Tabelle base (implementazione corrente)
knowledge_bases, workflows, files, manifests

-- Tabelle future (preparate ma non implementate)
visualizations, segments, cards, monitors,
schedules, events, analytics, user_preferences
```

---

## ðŸ“š DOCUMENTAZIONE RICHIESTA

### **Tecnica**
- [ ] Architecture Decision Records (ADRs)
- [ ] API Reference completa
- [ ] Database schema documentation
- [ ] Deployment guide
- [ ] Troubleshooting guide

### **User**
- [ ] User manual completo
- [ ] Quick start guide
- [ ] Video tutorials
- [ ] FAQ section
- [ ] Best practices guide

---

## ðŸŽ¯ CRITERI DI SUCCESSO FINALI

### **Funzionali**
- âœ… Tutti i workflow modes funzionano correttamente
- âœ… Parsing accurato per tutti i formati supportati
- âœ… UI intuitiva e responsive
- âœ… Download e preview file funzionanti
- âœ… Error handling robusto

### **Non-Funzionali**
- âœ… Performance: < 10 min per workflow standard
- âœ… Reliability: 99.9% uptime
- âœ… Security: Nessuna vulnerabilitÃ  critica
- âœ… Usability: User satisfaction > 85%
- âœ… Maintainability: Code coverage > 80%

---

## ðŸš€ PROSSIMI PASSI

1. **Review e Approvazione Piano**: Discussione e finalizzazione
2. **Setup Ambiente**: Preparazione branch e tooling
3. **Kick-off Fase 0**: Inizio implementazione
4. **Daily Standups**: Tracking progresso quotidiano
5. **Weekly Reviews**: Revisione settimanale e adattamenti

---

*Questo documento sarÃ  aggiornato durante l'implementazione per riflettere cambiamenti e decisioni prese durante lo sviluppo.*

**Versione**: 1.0
**Ultima Modifica**: 2025-08-14
**Autori**: Team Development
**Status**: Draft - In Review
